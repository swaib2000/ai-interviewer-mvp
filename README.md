# AI-Driven Automated Interviewer for Project Presentations

<img width="1441" height="752" alt="image" src="https://github.com/user-attachments/assets/3505c779-209e-4fc5-a09a-ce52ec39c1cc" />

An AI-powered system that **observes a studentâ€™s live project presentation**, understands on-screen content, and **conducts an adaptive technical interview** in real time.
The system integrates **screen capture, OCR-based context extraction, LLM-driven question generation, session orchestration, and a live dashboard**, making it suitable for hackathons, interviews, and academic demos.

<img width="1600" height="862" alt="image" src="https://github.com/user-attachments/assets/49e53b71-07fe-4cac-93d8-641b8707122f" />



## ğŸš€ Key Features

- ğŸ–¥ **Live Screen Capture**
  - Periodically captures a selected region of the presenterâ€™s screen.
- ğŸ” **On-Screen Content Understanding**
  - Extracts textual context from the screen using OCR (when enabled).
- ğŸ¤– **AI Interviewer**
  - Generates context-aware technical questions using a Large Language Model (LLM).
  - Automatically ramps question difficulty across the session.
- ğŸ§  **Session Orchestration**
  - Handles start / pause / resume / stop lifecycle reliably.
- ğŸ“Š **Interactive Dashboard**
  - Displays screen snapshot, OCR highlights, interview questions, transcript, logs, and metrics.
- ğŸ§© **Extensible Architecture**
  - Speech-to-Text (STT), scoring, and report generation can be added cleanly.

---

## ğŸ§± High-Level Architecture
```text
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Screen UI   â”‚  â† Streamlit dashboard
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Orchestrator       â”‚
â”‚  (control loop)     â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
       â”‚      â”‚
       â–¼      â–¼
    Screen  LLM Interviewer
    Capture  (Question Gen)
       â”‚
       â–¼
     OCR

```
---

## ğŸ“ Project Structure

```text
ai-interviewer-mvp/
â”‚
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ main.py                # Streamlit entry point (UI + dashboard)
â”‚   â”œâ”€â”€ state.py               # Central application state (single source of truth)
â”‚   â”‚
â”‚   â”œâ”€â”€ logic/
â”‚   â”‚   â”œâ”€â”€ orchestrator.py    # Control loop (session lifecycle, timing, routing)
â”‚   â”‚   â””â”€â”€ llm_interviewer.py # LLM-based question generation
â”‚   â”‚
â”‚   â”œâ”€â”€ capture/
â”‚   â”‚   â””â”€â”€ screen.py          # Screen capture utilities (live snapshots)
â”‚   â”‚
â”‚   â””â”€â”€ assets/                # Runtime-generated artifacts (gitignored)
â”‚       â””â”€â”€ latest_frame.png
â”‚
â”œâ”€â”€ requirements.txt           # Python dependencies
â”œâ”€â”€ README.md                  # Project documentation
â””â”€â”€ .gitignore                 # Git ignore rules
```



---

## ğŸ“„ File-by-File Explanation

### `app/main.py` â€” **Streamlit UI & Entry Point**
- Entry point of the application.
- Defines the dashboard layout:
  - Live screen snapshot
  - OCR highlights
  - Current interview question
  - Transcript and metrics
  - System logs
- Provides session controls:
  - Start / Pause / Resume / Stop / Clear
- Triggers the orchestrator loop on every Streamlit rerun.

---

### `app/state.py` â€” **Central State Management**
- Defines the `AppState` dataclass.
- Acts as the **single source of truth** for:
  - Session status
  - Screen capture metadata
  - OCR text and highlights
  - Transcript
  - Interview questions and difficulty
  - Metrics (OCR calls, LLM calls, latency)
  - System logs
- Ensures clean separation between UI and logic.

---

### `app/logic/orchestrator.py` â€” **System Orchestration**
- Core control loop of the system.
- Responsibilities:
  - Session lifecycle management
  - Periodic screen capture
  - OCR invocation
  - LLM question generation
  - Throttling, timing, and state updates
- Designed as a safe, tick-based loop compatible with Streamlit.

---

### `app/logic/llm_interviewer.py` â€” **AI Question Generator**
- Handles all LLM interactions.
- Uses OCR context and session state to generate:
  - A single, focused technical interview question at a time.
- Uses OpenAI APIs with graceful fallback if quota or API key is unavailable.

---

### `app/capture/screen.py` â€” **Screen Capture Utility**
- Captures the full screen or a specified region.
- Uses OS-native screen capture for reliability.
- Writes images atomically to prevent corrupted reads.
- Returns image path and dimensions for UI rendering.

---

### `app/assets/` â€” **Runtime Artifacts (Ignored by Git)**
- Stores temporary files such as:
  - Latest screenshots
  - Audio files (future STT)
- Automatically created at runtime.
- Excluded via `.gitignore`.

---

## âš™ï¸ Installation & Setup

### 1 Clone the Repository
```bash
git clone https://github.com/swaib2000/ai-interviewer-mvp.git
cd ai-interviewer-mvp 
```
### 2 Create & Activate Virtual Environment (Recommended)
python3 -m venv venv
source venv/bin/activate

### 3 Install Dependencies
pip install -r requirements.txt

### 4 Set Environment Variables
Set your OpenAI API key (required for LLM question generation):
export OPENAI_API_KEY="your_openai_api_key"

### 5 Run the Application
PYTHONPATH=. streamlit run app/main.py

// The Streamlit dashboard will open in your browser.



